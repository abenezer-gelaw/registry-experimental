{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(not isinstance(5, int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import dbscan\n",
    "from strsimpy.sorensen_dice import SorensenDice\n",
    "from sklearn.metrics.cluster import homogeneity_score\n",
    "from sklearn.metrics.cluster import completeness_score \n",
    "from sklearn.metrics.cluster import v_measure_score\n",
    "from sklearn.cluster import dbscan\n",
    "\n",
    "tagged_df = pd.read_csv (r'/home/gelaw/work-stuff/gocode/src/registry-experimental/consistency/analysis/vocab1000.csv')\n",
    "tagged_df = tagged_df.drop(tagged_df.index[1000:])\n",
    "word_labels = tagged_df.iloc[:, 0]\n",
    "word_labels = word_labels.to_numpy()\n",
    "tagged_words = tagged_df.iloc[:, 1]\n",
    "tagged_words = tagged_words.to_numpy()\n",
    "data = tagged_words\n",
    "data = data[1:30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(len(data)).reshape(-1, 1)\n",
    "dice = SorensenDice(2)\n",
    "def compute_predicted_lables(data, algorithm, dbscan_eps, dbscan_min_samples):\n",
    "    db = dbscan(data, metric=algorithm, eps=dbscan_eps, min_samples=dbscan_min_samples, algorithm='brute')\n",
    "    return db\n",
    "def extract_indices_dice(x, y):\n",
    "    i, j = int(x[0]), int(y[0])     # extract indices\n",
    "    return dice.distance(data[i], data[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abandon' 'abandoning' 'Abort' 'abort' 'aborted' 'About' 'about' 'Above'\n",
      " 'Absence' 'Absent' 'absentee' 'Absolute' 'absolutely' 'Abstain' 'Abuse'\n",
      " 'abusive' 'Accelerator' 'accelerator' 'accelerators' 'Accelerators'\n",
      " 'accept' 'acceptable' 'Accepted' 'accepts' 'Access' 'access' 'Accessed'\n",
      " 'Accesses' 'Accessibility']\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lables = compute_predicted_lables(data = X, algorithm = extract_indices_dice, dbscan_eps = .3, dbscan_min_samples = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "print(len(lables[1]))\n",
    "assert(len(lables[1]) == len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abandon' 'abandoning' 'Abort' 'abort' 'aborted' 'About' 'about' 'Above'\n",
      " 'Absence' 'Absent' 'absentee' 'Absolute' 'absolutely' 'Abstain' 'Abuse'\n",
      " 'abusive' 'Accelerator' 'accelerator' 'accelerators' 'Accelerators'\n",
      " 'accept' 'acceptable' 'Accepted' 'accepts' 'Access' 'access' 'Accessed'\n",
      " 'Accesses' 'Accessibility']\n"
     ]
    }
   ],
   "source": [
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  abandon\n",
      "0 :  abandoning\n",
      "1 :  Abort\n",
      "1 :  abort\n",
      "1 :  aborted\n",
      "2 :  About\n",
      "2 :  about\n",
      "-1 :  Above\n",
      "3 :  Absence\n",
      "3 :  Absent\n",
      "-1 :  absentee\n",
      "4 :  Absolute\n",
      "4 :  absolutely\n",
      "-1 :  Abstain\n",
      "-1 :  Abuse\n",
      "-1 :  abusive\n",
      "5 :  Accelerator\n",
      "5 :  accelerator\n",
      "5 :  accelerators\n",
      "5 :  Accelerators\n",
      "6 :  accept\n",
      "6 :  acceptable\n",
      "-1 :  Accepted\n",
      "6 :  accepts\n",
      "7 :  Access\n",
      "7 :  access\n",
      "7 :  Accessed\n",
      "7 :  Accesses\n",
      "-1 :  Accessibility\n"
     ]
    }
   ],
   "source": [
    "dictionary  = {}\n",
    "for j in range(len(data)):\n",
    "    word_label = lables[1][j]\n",
    "    print(word_label,\": \", data[j])\n",
    "    if word_label in dictionary:\n",
    "        dictionary[word_label].append(data[j])\n",
    "        \n",
    "    else:\n",
    "        dictionary[word_label] = [data[j]]\n",
    "#print(dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = []\n",
    "for key, value in dictionary.items():\n",
    "    for word in value:\n",
    "        l2.append(word)\n",
    "l2.sort()\n",
    "data.sort()\n",
    "for word1 in l2:\n",
    "    for word2 in data:\n",
    "        if word1 not in data or word2 not in l2:\n",
    "            print(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in l2:\n",
    "    if i not in data:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data:\n",
    "    if i not in l2:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 4), (1, 2), (2, 1)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "lst = [1,1,2, 3, 3,3, 3]\n",
    "wordc =Counter(lst).most_common()\n",
    "print(wordc)\n",
    "#c.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, labels = data, lables\n",
    "word_groups  = {}\n",
    "for j in range(len(words)):\n",
    "    word_label = labels[1][j]\n",
    "\n",
    "    if word_label in word_groups:\n",
    "        word_groups[word_label].append(words[j])\n",
    "                \n",
    "    else:\n",
    "        word_groups[word_label] = [words[j]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['Abort', 'About'], 1: ['Above', 'Absence', 'Absent'], 2: ['Absolute', 'Abstain'], -1: ['Abuse', 'Accepted', 'Accesses', 'Accessibility', 'abandon', 'abusive', 'access'], 3: ['Accelerator', 'Accelerators'], 4: ['Access', 'Accessed'], 5: ['abandoning', 'abort', 'aborted', 'about'], 6: ['absentee', 'absolutely', 'accelerator'], 7: ['accelerators', 'accept', 'acceptable', 'accepts']}\n"
     ]
    }
   ],
   "source": [
    "print(word_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "new_dicitionary = {}\n",
    "for k in word_groups.keys():\n",
    "    value = word_groups[k]\n",
    "    if len(Counter(value).most_common())  > 1:\n",
    "        word, count =Counter(value).most_common()[0] \n",
    "        if count > 1:\n",
    "            new_dicitionary[word] = value\n",
    "        else:\n",
    "            value.sort()\n",
    "            new_dicitionary[value[0]] = value\n",
    "\n",
    "print(len(new_dicitionary.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Abort': ['Abort', 'About'], 'Above': ['Above', 'Absence', 'Absent'], 'Absolute': ['Absolute', 'Abstain'], 'Abuse': ['Abuse', 'Accepted', 'Accesses', 'Accessibility', 'abandon', 'abusive', 'access'], 'Accelerator': ['Accelerator', 'Accelerators'], 'Access': ['Access', 'Accessed'], 'abandoning': ['abandoning', 'abort', 'aborted', 'about'], 'absentee': ['absentee', 'absolutely', 'accelerator'], 'accelerators': ['accelerators', 'accept', 'acceptable', 'accepts']}\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(new_dicitionary)\n",
    "print(len(new_dicitionary.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Abort': 1, 'About': 1}\n",
      "{'Above': 1, 'Absence': 1, 'Absent': 1}\n",
      "{'Absolute': 1, 'Abstain': 1}\n",
      "{'Abuse': 1, 'Accepted': 1, 'Accesses': 1, 'Accessibility': 1, 'abandon': 1, 'abusive': 1, 'access': 1}\n",
      "{'Accelerator': 1, 'Accelerators': 1}\n",
      "{'Access': 1, 'Accessed': 1}\n",
      "{'abandoning': 1, 'abort': 1, 'aborted': 1, 'about': 1}\n",
      "{'absentee': 1, 'absolutely': 1, 'accelerator': 1}\n",
      "{'accelerators': 1, 'accept': 1, 'acceptable': 1, 'accepts': 1}\n"
     ]
    }
   ],
   "source": [
    "for _, value in new_dicitionary.items():\n",
    "    print(dict(Counter(value)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
